# In[]import matplotlib.pyplot as pltimport numpy as npimport torchimport torchvisionimport torchvision.transforms as transformsfrom operator import itemgetterimport matplotlib as mplimport mathfrom torch import nnfrom torch.cuda import ampfrom tqdm import tqdm, trangeimport gcfrom torch.nn import functional as Ffrom torch.utils.data import random_splitfrom copy import deepcopysys.path.insert(1, './Utils/')import Unetimport Plotimport Diffusionimport loaderimport cfgBATCH_SIZE = 64# In[] Load dataDATASET = 'CIFAR'config = cfg.load_config(DATASET)suffix = '{:s}_{:d}_newUnet/'.format(config.DATASET,                                     config.n_images)config.DEVICE = 'cuda:1'loading_func = 'loader.load_{:s}(config, loadtest=True)'.format(config.DATASET)testset = Nonetrainset, testset = eval(loading_func)# In[]if __name__ == '__main__':    trainloader = torch.utils.data.DataLoader(trainset,                                              batch_size=config.BATCH_SIZE,                                              shuffle=True,                                              num_workers=1,                                              pin_memory=False)    if testset is not None:        testloader = torch.utils.data.DataLoader(testset,                                                  batch_size=config.BATCH_SIZE,                                                  shuffle=False,                                                  num_workers=2,                                                  pin_memory=False)# Build loadersnb = int(len(trainset) * 0.2)trainset, valset = random_split(trainset, [len(trainset)-nb, nb])trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,                                          shuffle=True, num_workers=1,                                          pin_memory=False)valloader = torch.utils.data.DataLoader(valset, batch_size=BATCH_SIZE,                                          shuffle=True, num_workers=1,                                          pin_memory=False)# In[]class ResNet(nn.Module):    def __init__(self):        super().__init__()        base = torchvision.models.resnet18(pretrained=True)                if DATASET == 'MNIST':  # FOR MNIST            self.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)            self.base = nn.Sequential(*list(base.children())[1:-1])        else:   # For others            self.base = nn.Sequential(*list(base.children())[:-1])                in_features = base.fc.in_features        self.drop = nn.Dropout()        self.final = nn.Linear(in_features, 2)        def forward(self,x):        if DATASET == 'MNIST':            x = self.conv1(x) # For MNIST        x = self.base(x)        x = self.drop(x.view(-1,self.final.in_features))        return self.final(x)    model = ResNet().to(DEVICE)criterion = nn.CrossEntropyLoss()param_groups = [    {'params':model.base.parameters(),'lr':.0001},    {'params':model.final.parameters(),'lr':.001}]optimizer = torch.optim.Adam(param_groups)lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)states = {}# In[]tf = torchvision.transforms.Resize(224)     # Resize the image (maybe not necessary)best_val_acc = -1000best_val_model = Nonefor epoch in range(10):      model.train(True)    train_loss = 0.0    train_acc = 0        for i, data in enumerate(trainloader, 0):        inputs, labels = data        inputs = inputs.to(DEVICE)        inputs = tf(inputs)        labels = labels.to(DEVICE)                # Compute loss and update parameters        optimizer.zero_grad()        outputs = model(inputs)        loss = criterion(outputs, labels.long())        loss.backward()        optimizer.step()        train_loss += loss.item() * inputs.size(0)        out = torch.argmax(outputs.detach(),dim=1)                train_acc += (labels==out).sum().item()    print(f"Train loss {epoch+1}: {train_loss/len(trainset)}, Train Acc:{train_acc*100/len(trainset)}%")        correct = 0    model.train(False)    with torch.no_grad():        for inputs, labels in valloader:            inputs = inputs.to(DEVICE)            inputs = tf(inputs)            out = model(inputs).cpu()            out = torch.argmax(out,dim=1)            acc = (out==labels).sum().item()            correct += acc    print(f"Val accuracy:{correct*100/len(valset)}%")    if correct>best_val_acc:        best_val_acc = correct        best_val_model = deepcopy(model.state_dict())    lr_scheduler.step()    print('Finished Training')# In[]# Test accuracycorrect = 0model.train(False)with torch.no_grad():    for inputs,labels in testloader:        inputs = inputs.to(DEVICE)        out = model(inputs).cpu()        out = torch.argmax(out,dim=1)        acc = (out==labels).sum().item()        correct += accprint(f"Test accuracy:{correct*100/len(testset)}%")# In[]# Save modelpath_save_classif = '../Saves/Models/Classification/'torch.save(model.state_dict(), path_save_classif + 'ResNet18_' + suffix)